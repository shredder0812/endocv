{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1LrqSONdjdBwQHdDvcaIEWXwmweEp8Rz8",
      "authorship_tag": "ABX9TyMSgVNK3f0ZAjxe/2LoSuCQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shredder0812/endocv/blob/main/done_strongsort.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ENDOCV/Daday_3.mp4 /content/drive/MyDrive/ENDOCV/2602/detect/train2/weights/best.pt /content"
      ],
      "metadata": {
        "id": "pLnOC3NAaeqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install ultralytics\n",
        "!pip install boxmot\n"
      ],
      "metadata": {
        "id": "Lj6H6zm8bXso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KeeganFernandesWork/yolo_tracking\n",
        "%cd yolo_tracking\n",
        "!pip install -r requirements.txt\n",
        "!pip install ."
      ],
      "metadata": {
        "id": "l4oTxlPHhfPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from boxmot import (OCSORT, BoTSORT, BYTETracker, DeepOCSORT, StrongSORT,\n",
        "                    create_tracker, get_tracker_config)\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "import datetime\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ],
      "metadata": {
        "id": "QoMF29TgOB9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from boxmot import StrongSORT\n",
        "from pathlib import Path\n",
        "from time import perf_counter\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class Colors:\n",
        "    def __init__(self, num_colors=80):\n",
        "        self.num_colors = num_colors\n",
        "        self.color_palette = self.generate_color_palette()\n",
        "\n",
        "\n",
        "    def generate_color_palette(self):\n",
        "        hsv_palette = np.zeros((self.num_colors, 1, 3), dtype=np.uint8)\n",
        "        hsv_palette[:, 0, 0] = np.linspace(0, 180, self.num_colors, endpoint=False)\n",
        "        hsv_palette[:, :, 1:] = 255\n",
        "        bgr_palette = cv2.cvtColor(hsv_palette, cv2.COLOR_HSV2BGR)\n",
        "        return bgr_palette.reshape(-1, 3)\n",
        "\n",
        "    def __call__(self, class_id):\n",
        "        color = tuple(map(int, self.color_palette[class_id]))\n",
        "        return color\n",
        "\n",
        "class ObjectDetection:\n",
        "    def __init__(self, model_weights=\"yolov8s.pt\", capture_index=0):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        print(\"Using Device: \", self.device)\n",
        "        self.model = self.load_model(model_weights)\n",
        "        self.classes = self.model.names\n",
        "        self.classes[0] = 'polyp'\n",
        "        self.colors = Colors(len(self.classes))\n",
        "        self.font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        self.capture_index = capture_index\n",
        "        self.cap = self.load_capture()\n",
        "        reid_weights = Path(\"osnet_x0_25_msmt17.pt\")\n",
        "\n",
        "        self.tracker = StrongSORT(reid_weights,\n",
        "                                  torch.device(self.device),\n",
        "                                  fp16 = False,\n",
        "                                  )\n",
        "\n",
        "    def load_model(self, weights):\n",
        "        model = YOLO(weights)\n",
        "        model.fuse()\n",
        "        return model\n",
        "\n",
        "    def predict(self, frame):\n",
        "        results = self.model(frame, stream=True, verbose=False, conf=0.45, line_width=1)\n",
        "        return results\n",
        "\n",
        "    def draw_tracks(self, frame, tracks):\n",
        "        for track in tracks:\n",
        "            x1, y1, x2, y2 = int(track[0]), int(track[1]), int(track[2]), int(track[3])\n",
        "            id = int(track[4])\n",
        "            conf = track[5]\n",
        "            class_id = int(track[6])\n",
        "            class_name = self.classes[class_id]\n",
        "            cv2.rectangle(frame, (x1,y1), (x2, y2), self.colors(class_id), 2)\n",
        "            label = f'{class_name} {id}'\n",
        "            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "            cv2.rectangle(frame, (x1, y1-h-15), (x1+w, y1), self.colors(class_id), -1)\n",
        "            cv2.putText(frame, label, (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255) , 2)\n",
        "        return frame\n",
        "\n",
        "    def load_capture(self):\n",
        "        cap = cv2.VideoCapture(self.capture_index)\n",
        "        assert cap.isOpened()\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
        "        self.writer = cv2.VideoWriter(fr'strongsort_daday3.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "        return cap\n",
        "\n",
        "    def __call__(self):\n",
        "        tracker = self.tracker\n",
        "        while True:\n",
        "            start_time = perf_counter()\n",
        "            ret, frame = self.cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            cv2.rectangle(frame, (0,30), (220,80), (255,255,255),-1 )\n",
        "            detections = self.predict(frame)\n",
        "            for dets in detections:\n",
        "                tracks = tracker.update(dets.boxes.data.to(\"cpu\").numpy(), frame)\n",
        "                if len(tracks.shape) == 2 and tracks.shape[1] == 8:\n",
        "                    frame = self.draw_tracks(frame, tracks)\n",
        "            end_time = perf_counter()\n",
        "            fps = 1/np.round(end_time - start_time, 2)\n",
        "            cv2.putText(frame, f'FPS: {int(fps)}', (20,70), self.font, 1.5, (0,255,0), 2)\n",
        "            self.writer.write(frame)\n",
        "            #cv2.imshow('YOLOv8 Tracking', frame)\n",
        "            if cv2.waitKey(5) & 0xFF == 27:\n",
        "                break\n",
        "        self.cap.release()\n",
        "        self.writer.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "test_vid = \"/content/Daday_3.mp4\"\n",
        "model_weights = \"/content/best.pt\"\n",
        "detector = ObjectDetection(model_weights, test_vid)\n",
        "detector()"
      ],
      "metadata": {
        "id": "3vP2Wb9ubRG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7942f2b8-3634-48e6-8712-a2803eafb3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device:  cuda\n",
            "Model summary (fused): 268 layers, 68124531 parameters, 0 gradients, 257.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sSwXSUlj4_tHZequ_iZ8w_Jh0VaRQMqF\n",
            "To: /content/yolo_tracking/osnet_x0_25_msmt17.pt\n",
            "100%|██████████| 3.06M/3.06M [00:00<00:00, 101MB/s]\n",
            "\u001b[32m2024-02-26 03:53:19.075\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m207\u001b[0m - \u001b[32m\u001b[1mSuccessfully loaded pretrained weights from \"osnet_x0_25_msmt17.pt\"\u001b[0m\n",
            "\u001b[32m2024-02-26 03:53:19.080\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m211\u001b[0m - \u001b[33m\u001b[1mThe following layers are discarded due to unmatched keys or layer size: ('classifier.weight', 'classifier.bias')\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}